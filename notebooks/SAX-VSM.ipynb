{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora, models, similarities\n",
    "from seismic.observations import ObservationDAO, ObservationDAOError\n",
    "from seismic.detector import SaxDetect, StaLtaDetect, DetectorError\n",
    "from seismic.sax import Paa, Sax\n",
    "from seismic.detector.utils import make_series\n",
    "\n",
    "base_dir = \"../sample/_vsm/\"\n",
    "obs_list = os.listdir(base_dir)\n",
    "bandpass = (5, 10)\n",
    "alphabet = \"abcdefg\"\n",
    "paa_int = 50\n",
    "rows = 3\n",
    "cols = 3\n",
    "obs = {}\n",
    "for f in obs_list:\n",
    "    obs[f] = ObservationDAO(os.path.join(base_dir, f))\n",
    "series = {}\n",
    "for n, o in obs.items():  # Use SaxDetect series property to get a series\n",
    "    series[n] = make_series(o.stream[0].data, o.stats.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Events using SaxDetect and recalculate SAX strings for events only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sax_str = {}\n",
    "for n, o in obs.items():\n",
    "    # Assuming one event per obs as this is known for our test daat\n",
    "    o.bandpass(*bandpass)\n",
    "    det = SaxDetect(o.stream[0].data, o.stats.sampling_rate)\n",
    "    evt = det.slice(*det.detect(alphabet, paa_int).__next__())\n",
    "    p = Paa(evt)\n",
    "    s = Sax(p(50))\n",
    "    sax_str[n] = \"\".join([i for i in s(alphabet)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cal.z',\n",
       " 'cao.z',\n",
       " 'cda.z',\n",
       " 'cdv.z',\n",
       " 'cmn.z',\n",
       " 'cps.z',\n",
       " 'cva.z',\n",
       " 'cvl.z',\n",
       " 'cvy.z',\n",
       " 'elk.z',\n",
       " 'knb.z',\n",
       " 'lac.z',\n",
       " 'mnv.z']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus = []\n",
    "docs_in_corpus = []\n",
    "w = 6  # Length of words\n",
    "for name in sorted(sax_str.keys()):\n",
    "    s = sax_str[name]\n",
    "    bow = []\n",
    "    for i in range(0, len(s) - w): # -1\n",
    "        bow.append(s[i:i+w])\n",
    "    raw_corpus.append(bow)\n",
    "    docs_in_corpus.append(name)\n",
    "docs_in_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.0)\tcal.z\n",
      "(7, 0.99998105)\tcvl.z\n",
      "(12, 0.99748516)\tmnv.z\n",
      "(3, 0.99479204)\tcdv.z\n",
      "(11, 0.96801895)\tlac.z\n",
      "(8, 0.96459877)\tcvy.z\n",
      "(5, 0.96159577)\tcps.z\n",
      "(6, 0.94858986)\tcva.z\n",
      "(9, 0.90870178)\telk.z\n",
      "(2, 0.79671615)\tcda.z\n",
      "(1, 0.78651863)\tcao.z\n",
      "(4, 0.59922862)\tcmn.z\n",
      "(10, 0.48884442)\tknb.z\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(raw_corpus[1:])\n",
    "corpus = [dictionary.doc2bow(t) for t in raw_corpus]\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "\n",
    "query = dictionary.doc2bow(raw_corpus[0])\n",
    "vec_qry = lsi[query]\n",
    "\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "sims = index[vec_qry]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for s in sims:\n",
    "    print(\"{}\\t{}\".format(s, docs_in_corpus[s[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic",
   "language": "python",
   "name": "seismic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
